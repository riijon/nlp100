{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章: ベクトル空間法 (II)\n",
    "\n",
    "第10章では，前章に引き続き単語ベクトルの学習に取り組む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90. word2vecによる学習\n",
    "81で作成したコーパスに対してword2vecを適用し，単語ベクトルを学習せよ．さらに，学習した単語ベクトルの形式を変換し，86-89のプログラムを動かせ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://rare-technologies.com/word2vec-tutorial/\n",
    "with open('81.txt', 'r') as f:\n",
    "    corpus = [f.read().split()]\n",
    "model = Word2Vec(corpus, min_count=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.35321126e-03,   7.24946403e-06,  -1.00240693e-03,\n",
       "         1.71894359e-03,   2.60639982e-03,   4.54979250e-03,\n",
       "         2.76367622e-03,   1.16067892e-03,  -4.56093159e-03,\n",
       "         2.28043390e-03,  -2.84206634e-03,   4.03411046e-04,\n",
       "         2.00514449e-03,   3.51159112e-03,   4.71542217e-03,\n",
       "        -1.17139041e-03,   5.38714649e-03,  -5.43413043e-04,\n",
       "        -6.97838608e-04,   4.23885277e-03,  -2.26624170e-03,\n",
       "        -2.62963469e-03,  -2.40363809e-03,  -1.88103202e-03,\n",
       "        -4.21376433e-03,  -4.56124824e-03,  -3.34482896e-03,\n",
       "        -4.16845037e-03,  -4.37373761e-03,   9.01171763e-04,\n",
       "         4.30961140e-03,  -6.49189693e-04,  -1.51208998e-03,\n",
       "        -1.78049924e-03,   1.85211143e-03,   3.75750707e-03,\n",
       "        -5.62814949e-03,   1.86741853e-03,  -4.62834537e-03,\n",
       "        -4.38138936e-03,  -7.36817543e-04,  -3.35923303e-03,\n",
       "         3.46384384e-03,  -3.02884099e-03,   2.75690662e-04,\n",
       "        -3.31420754e-03,   1.73456431e-03,  -2.17259116e-03,\n",
       "        -1.79928832e-03,  -3.57838650e-03,   1.34452083e-03,\n",
       "         3.18233622e-03,   2.19305721e-03,  -5.01941377e-03,\n",
       "         3.41415685e-03,  -5.00417547e-03,   3.88640998e-04,\n",
       "         1.18963828e-04,   1.91080500e-03,   4.10490262e-04,\n",
       "        -4.16974435e-05,   1.45073212e-03,   1.19704287e-03,\n",
       "         1.10396626e-03,   3.80577403e-03,   3.23443394e-03,\n",
       "        -2.01867870e-03,  -3.42219020e-04,   1.18146697e-03,\n",
       "         3.34658846e-03,   4.75970469e-03,   4.34370246e-03,\n",
       "         8.73754791e-04,  -4.08221222e-03,   1.87698833e-03,\n",
       "        -4.99231881e-03,  -4.82389238e-04,  -3.98352073e-04,\n",
       "         2.91397166e-03,  -1.07766027e-04,   8.26866948e-04,\n",
       "         2.81148986e-03,   8.86081601e-04,   4.30208631e-03,\n",
       "        -2.14660453e-04,   2.49667931e-03,  -2.12219427e-03,\n",
       "        -2.17961171e-03,   4.29903669e-03,  -4.81316587e-03,\n",
       "        -5.08360611e-03,  -1.43398254e-04,   2.79794657e-03,\n",
       "        -7.60299154e-04,   4.19183215e-03,  -2.74568703e-03,\n",
       "        -4.41253884e-03,   1.30943581e-03,   2.39553163e-03,\n",
       "         7.28374056e-04], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 86 ベクトル表示\n",
    "model['United_States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.067391358831258255"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 87 コサイン類似度 \n",
    "model.similarity(\"United_States\", \"U.S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Play/Create', 0.4888457953929901),\n",
       " ('Crossings\"', 0.4459366798400879),\n",
       " ('conservatism\"characterizing', 0.43599146604537964),\n",
       " ('Mathis\"', 0.4313720464706421),\n",
       " ('springline', 0.41823285818099976),\n",
       " ('lila)', 0.4162786602973938),\n",
       " ('tape-manipulated', 0.41262805461883545),\n",
       " ('Piasecki', 0.4124037027359009),\n",
       " ('1909–1913)', 0.4096204340457916),\n",
       " ('Cen', 0.3987789452075958)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 88 類似度 top10\n",
    "model.most_similar(positive=['England'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TASC-01-SCF', 0.44708970189094543),\n",
       " ('dockworkers', 0.43916040658950806),\n",
       " ('Routemasters', 0.43558230996131897),\n",
       " ('title.\"</noinclude>', 0.4306522607803345),\n",
       " ('Standartenführer', 0.418748140335083),\n",
       " ('Trillions', 0.4170217216014862),\n",
       " ('Up\")', 0.4168779253959656),\n",
       " ('\"Bellum', 0.41194450855255127),\n",
       " ('Mutolo’s', 0.4111941456794739),\n",
       " ('factors', 0.4057306945323944)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 89 アナロジー top10\n",
    "model.most_similar(positive=['Spain', 'Athens'], negative=['Madrid'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 91. アナロジーデータの準備\n",
    "単語アナロジーの評価データをダウンロードせよ．このデータ中で\": \"で始まる行はセクション名を表す．例えば，\": capital-common-countries\"という行は，\"capital-common-countries\"というセクションの開始を表している．ダウンロードした評価データの中で，\"family\"というセクションに含まれる評価事例を抜き出してファイルに保存せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('questions-words.txt', 'r') as f:\n",
    "    sections = f.read().split(':')\n",
    "    for section in sections:\n",
    "        if 'family' in section.split('\\n')[0]:\n",
    "            family = \"\\n\".join(section.split('\\n')[1:])\n",
    "with open('family.txt', 'w') as f:\n",
    "    f.write(family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 92. アナロジーデータへの適用\n",
    "91で作成した評価データの各事例に対して，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('family.txt', 'r') as f:\n",
    "    family = [x[:-1].split() for x in f.readlines()]\n",
    "len(family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_contain(words):\n",
    "    for w in words:\n",
    "        if not w in model:\n",
    "            return False \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('92.txt', 'w') as f:\n",
    "    for line in family:\n",
    "        c1, c2, c3, c4 = line\n",
    "        nomatch = model.doesnt_match(line)\n",
    "        if check_contain(line):\n",
    "            w, p = model.most_similar(positive=[c2, c3], negative=[c1], topn=1)[0]\n",
    "            line = str(w) + \"\\t\" + str(p) + \"\\n\"\n",
    "        else:\n",
    "            line = \"NoMatch\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93. アナロジータスクの正解率の計算\n",
    "92で作ったデータを用い，各モデルのアナロジータスクの正解率を求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count93 = 0\n",
    "with open('92.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        w = line[:-1].split()[0]\n",
    "        ans_w = family[i][3]\n",
    "        if w != \"NoMatch\" and w == ans_w:\n",
    "            count93 += 1\n",
    "            print(\"match!!!!!\")\n",
    "count93 / len(family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 94. WordSimilarity-353での類似度計算\n",
    "The WordSimilarity-353 Test Collectionの評価データを入力とし，1列目と2列目の単語の類似度を計算し，各行の末尾に類似度の値を追加するプログラムを作成せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95. WordSimilarity-353での評価\n",
    "94で作ったデータを用い，各モデルが出力する類似度のランキングと，人間の類似度判定のランキングの間のスピアマン相関係数を計算せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 96. 国名に関するベクトルの抽出\n",
    "word2vecの学習結果から，国名に関するベクトルのみを抜き出せ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 97. k-meansクラスタリング\n",
    "96の単語ベクトルに対して，k-meansクラスタリングをクラスタ数k=5k=5として実行せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98. Ward法によるクラスタリング\n",
    "96の単語ベクトルに対して，Ward法による階層型クラスタリングを実行せよ．さらに，クラスタリング結果をデンドログラムとして可視化せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. t-SNEによる可視化\n",
    "96の単語ベクトルに対して，ベクトル空間をt-SNEで可視化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章: ベクトル空間法 (II)\n",
    "\n",
    "第10章では，前章に引き続き単語ベクトルの学習に取り組む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90. word2vecによる学習\n",
    "81で作成したコーパスに対してword2vecを適用し，単語ベクトルを学習せよ．さらに，学習した単語ベクトルの形式を変換し，86-89のプログラムを動かせ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://rare-technologies.com/word2vec-tutorial/\n",
    "with open('81.txt', 'r') as f:\n",
    "    corpus = [f.read().split()]\n",
    "model = Word2Vec(corpus, min_count=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.74452008e-03,   4.14247252e-03,  -1.90847181e-03,\n",
       "         4.92690550e-03,  -1.66915284e-04,  -2.07025977e-03,\n",
       "        -4.08928172e-04,   3.09598702e-03,   2.16265267e-04,\n",
       "        -4.32988349e-03,   2.14363984e-03,  -3.80866259e-04,\n",
       "         3.33504495e-03,  -4.16176999e-03,  -1.51679886e-03,\n",
       "         2.35196599e-03,   1.07113540e-03,   4.17051185e-03,\n",
       "        -4.32816334e-03,  -3.14497110e-03,   9.37194913e-04,\n",
       "        -7.68948055e-04,  -3.61964339e-03,   7.99834612e-04,\n",
       "         4.82065696e-03,  -9.44846310e-04,  -2.27891942e-04,\n",
       "         1.80317799e-03,  -4.52356879e-03,   1.69966195e-03,\n",
       "        -5.80497459e-03,  -5.35298139e-03,   3.81616876e-03,\n",
       "         4.19021538e-03,  -1.97405810e-03,   5.51197631e-03,\n",
       "        -3.72335850e-03,  -1.29071646e-03,  -1.52754062e-03,\n",
       "        -5.11130644e-03,   3.57222394e-03,   1.73195603e-03,\n",
       "        -4.50111739e-03,   1.14969956e-03,  -4.23314143e-03,\n",
       "         2.27533001e-03,   6.00323407e-03,  -2.74500740e-03,\n",
       "         3.50066344e-04,   3.18424281e-05,  -2.48250389e-03,\n",
       "        -4.73175943e-03,  -3.55730881e-03,   3.31820548e-03,\n",
       "         3.22973961e-03,   4.98825358e-03,  -2.43560108e-03,\n",
       "         3.70492297e-03,   1.85312680e-03,   8.87360249e-04,\n",
       "         2.92770041e-04,  -3.52224009e-03,  -1.98277901e-03,\n",
       "        -1.06777879e-03,  -4.52254573e-03,   3.57237551e-03,\n",
       "         3.31316725e-03,   3.56266391e-03,  -1.05345040e-03,\n",
       "        -6.80665544e-04,  -4.54158551e-04,   2.14705290e-03,\n",
       "        -5.07813692e-03,  -2.38902541e-03,   1.98972248e-03,\n",
       "        -2.71140132e-03,   3.98515025e-03,   2.26822420e-04,\n",
       "        -8.73260258e-04,  -1.36286765e-03,   3.09441146e-03,\n",
       "         5.48635982e-03,   2.17271643e-03,   4.72243410e-03,\n",
       "        -2.12694961e-03,  -3.66741861e-03,   2.81686289e-03,\n",
       "        -5.15379431e-03,   5.67932962e-04,   2.85776611e-03,\n",
       "         4.81269276e-03,  -4.61219717e-03,   4.11269983e-04,\n",
       "        -1.87461020e-03,  -3.87464231e-03,  -1.15557210e-04,\n",
       "         4.78540268e-03,   8.60944681e-04,   1.39961904e-03,\n",
       "        -2.56116083e-03], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 86 ベクトル表示\n",
    "model['United_States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18035988021980459"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 87 コサイン類似度 \n",
    "model.similarity(\"United_States\", \"U.S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wisconsin-Madison', 0.44466376304626465),\n",
       " ('audio-only', 0.44343793392181396),\n",
       " ('reentry', 0.4241366386413574),\n",
       " ('Lille', 0.41284117102622986),\n",
       " ('nasugdan', 0.40986520051956177),\n",
       " ('celibate', 0.4096040725708008),\n",
       " ('Touane', 0.4047726094722748),\n",
       " ('16-member', 0.400925874710083),\n",
       " ('wrestling', 0.4006977677345276),\n",
       " (\"Honey's\", 0.3988679051399231)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 88 類似度 top10\n",
    "model.most_similar(positive=['England'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imagine.', 0.45201873779296875),\n",
       " ('হিমু', 0.4420362114906311),\n",
       " ('Glinka)', 0.42740336060523987),\n",
       " ('Pacifique', 0.40670719742774963),\n",
       " ('20,000–30,000', 0.40599608421325684),\n",
       " ('Brutaal', 0.40582478046417236),\n",
       " ('Fuzhounese', 0.40473905205726624),\n",
       " ('bap', 0.4021039605140686),\n",
       " ('inquiry.', 0.4017986059188843),\n",
       " ('Krautfabrik', 0.40117621421813965)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 89 アナロジー top10\n",
    "model.most_similar(positive=['Spain', 'Athens'], negative=['Madrid'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 91. アナロジーデータの準備\n",
    "単語アナロジーの評価データをダウンロードせよ．このデータ中で\": \"で始まる行はセクション名を表す．例えば，\": capital-common-countries\"という行は，\"capital-common-countries\"というセクションの開始を表している．ダウンロードした評価データの中で，\"family\"というセクションに含まれる評価事例を抜き出してファイルに保存せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('questions-words.txt', 'r') as f:\n",
    "    sections = f.read().split(':')\n",
    "    for section in sections:\n",
    "        if 'family' in section.split('\\n')[0]:\n",
    "            family = \"\\n\".join(section.split('\\n')[1:])\n",
    "with open('family.txt', 'w') as f:\n",
    "    f.write(family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 92. アナロジーデータへの適用\n",
    "91で作成した評価データの各事例に対して，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('family.txt', 'r') as f:\n",
    "    family = [x[:-1].split() for x in f.readlines()]\n",
    "len(family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_contain(words):\n",
    "    for w in words:\n",
    "        if not w in model:\n",
    "            return False \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dusk\" 0.4291321039199829\n",
      "1984–1988) 0.42714399099349976\n",
      "Poules) 0.44175904989242554\n",
      "EMLL 0.4708064794540405\n",
      "Bhikkhus 0.4463440775871277\n",
      "NoMatch 0\n",
      "snowmobiles 0.4089697003364563\n",
      "sheeting 0.4304097294807434\n",
      "Altbayern 0.41197681427001953\n",
      "Altbayern 0.4615488648414612\n",
      "Janáček 0.4465686082839966\n",
      "Hocking 0.4841853976249695\n",
      "gridirons 0.44049376249313354\n",
      "Pooja 0.4197467267513275\n",
      "Enix's 0.4253019094467163\n",
      "snowmobiles 0.43248608708381653\n",
      "Polynesia 0.42437052726745605\n",
      "Airliners 0.4742032587528229\n",
      "FRAS 0.4796660542488098\n",
      "Opperman 0.46542245149612427\n",
      "“Measurements 0.4417111873626709\n",
      "brown-throated 0.46532654762268066\n",
      "Tribune-Herald 0.4832778871059418\n",
      "civil\" 0.4388255476951599\n",
      "Autonome 0.40952053666114807\n",
      "sadomasochism\" 0.4658799469470978\n",
      "NoMatch 0\n",
      "GOES-West 0.42592501640319824\n",
      "Intelligencer 0.4576433300971985\n",
      "Putting 0.4567410945892334\n",
      "Michelin 0.4614273011684418\n",
      "ION 0.45787280797958374\n",
      "inches\" 0.42312508821487427\n",
      "pretenders 0.43978092074394226\n",
      "Cebuano's 0.48285239934921265\n",
      "Quebecor 0.4230499863624573\n",
      "Spivey 0.47411537170410156\n",
      "mistrials 0.4146338403224945\n",
      "U-boat 0.45833340287208557\n",
      "Catopsalis 0.4480506181716919\n",
      "Akwa 0.4148007035255432\n",
      "fugitives 0.4429174065589905\n",
      "442/8 0.4484971761703491\n",
      "squirrels) 0.43742576241493225\n",
      "glume.\"T 0.45895782113075256\n",
      "differ 0.44055846333503723\n",
      "Stuf 0.4581805169582367\n",
      "NoMatch 0\n",
      "1623 0.4100222885608673\n",
      "$8.5 0.4342779219150543\n",
      "glume.\"T 0.4587043225765228\n",
      "Euripides’ 0.44733452796936035\n",
      "21.73% 0.43807539343833923\n",
      "Thues 0.4353078603744507\n",
      "Mushaira 0.43468403816223145\n",
      "Jean-Nicolas 0.5161541700363159\n",
      "Cartesian 0.4320821762084961\n",
      "TTBK1 0.4396800994873047\n",
      "assicurazione 0.4267531633377075\n",
      "joy. 0.43202146887779236\n",
      "Euripides’ 0.4411393105983734\n",
      "Genji 0.43843790888786316\n",
      "16×16) 0.43387648463249207\n",
      "Ashley-Cooper 0.43179282546043396\n",
      "Jacob's 0.44421789050102234\n",
      "Cali 0.4488886594772339\n",
      "undersampling 0.46231207251548767\n",
      "Confinement\" 0.42571502923965454\n",
      "NoMatch 0\n",
      "t\"3 0.46092045307159424\n",
      "Hellblazer\" 0.43402236700057983\n",
      "Indonesian-specific 0.45030707120895386\n",
      "off-beat 0.49430760741233826\n",
      "t\"3 0.46263033151626587\n",
      "598 0.416281521320343\n",
      "\"Microtus 0.4597574472427368\n",
      "t\"3 0.44151413440704346\n",
      "Grubbs 0.45053040981292725\n",
      "\"Kaminsaal\" 0.4488033652305603\n",
      "Washington) 0.4673343300819397\n",
      "t\"3 0.4460888206958771\n",
      "Pique 0.4515484869480133\n",
      "Pique 0.462032675743103\n",
      "t\"3 0.46090516448020935\n",
      "gynoid 0.45136570930480957\n",
      "uptake 0.4630318880081177\n",
      "uptake 0.43103039264678955\n",
      "coxae) 0.41287750005722046\n",
      "Perton 0.42904937267303467\n",
      "NoMatch 0\n",
      "demesne\" 0.43316471576690674\n",
      "debt-free 0.4903867244720459\n",
      "Harper 0.45157867670059204\n",
      "Jesualdo 0.4207029938697815\n",
      "cherry 0.4459191560745239\n",
      "Then-State 0.4574764668941498\n",
      "Khaffef 0.414398193359375\n",
      "jahez-e-fatimi\") 0.44061142206192017\n",
      "g-se 0.443995863199234\n",
      "Yoshimoto 0.45160460472106934\n",
      "Pangan 0.4380219280719757\n",
      "Alsace-Moselle) 0.435647189617157\n",
      "debt-free 0.4592178463935852\n",
      "desmodromic 0.43725988268852234\n",
      "Brak 0.48921436071395874\n",
      "environment\" 0.43472737073898315\n",
      "Kezef 0.4436395764350891\n",
      "Michael-Bruno 0.5056086778640747\n",
      "reteach 0.4485461711883545\n",
      "Yoshimoto 0.44606801867485046\n",
      "NoMatch 0\n",
      "Albano 0.41695207357406616\n",
      "Silimanite/ 0.43183690309524536\n",
      "Illusions 0.4340628981590271\n",
      "Litzen 0.4337595999240875\n",
      "Albano 0.4376399517059326\n",
      "ear\" 0.46639734506607056\n",
      "houses” 0.455848753452301\n",
      "Lacombe 0.443790078163147\n",
      "like...whoa! 0.42942243814468384\n",
      "Foglish 0.45398256182670593\n",
      "Pengshan 0.4222518801689148\n",
      "1975. 0.4575693607330322\n",
      "Cronkite 0.44271793961524963\n",
      "ethiofencarb 0.4461665749549866\n",
      "Skikda) 0.43485990166664124\n",
      "dependency-on-resource-owner 0.4793838858604431\n",
      "Skikda) 0.44631218910217285\n",
      "Derryvrane 0.4325888752937317\n",
      "10.10 0.45728302001953125\n",
      "Strwiaz 0.44329947233200073\n",
      "spokesman 0.4419722557067871\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "NoMatch 0\n",
      "prius 0.4613960385322571\n",
      "Villeneuve-de-la-Raho 0.44302552938461304\n",
      "THEM 0.4302729368209839\n",
      "Benedetti 0.46689313650131226\n",
      "Alakoro 0.44919145107269287\n",
      "Pays\" 0.45226404070854187\n",
      "all-seeing\" 0.5124917030334473\n",
      "[Together 0.44263485074043274\n",
      "queerly-shaped 0.44472020864486694\n",
      "mustn't 0.44997847080230713\n",
      "all-seeing\" 0.4743160009384155\n",
      "Sundazed 0.48125171661376953\n",
      "all-seeing\" 0.5268291234970093\n",
      "Judenthum 0.44301852583885193\n",
      "헌터스 0.4382461607456207\n",
      "Jehu 0.4493359327316284\n",
      "Baku-Tbilisi-Ceyhan 0.47316449880599976\n",
      "Dewayne 0.4242790937423706\n",
      "Balance 0.48351210355758667\n",
      "Walk\" 0.42284590005874634\n",
      "modeling\" 0.4448159635066986\n",
      "NoMatch 0\n",
      "Juhan 0.4526089131832123\n",
      "ow 0.4511388838291168\n",
      "leasing 0.4211368262767792\n",
      "Chunkara 0.45134150981903076\n",
      "Tennyson\" 0.44132179021835327\n",
      "-94.550092) 0.4417717158794403\n",
      "\"SHAQ!\" 0.44745397567749023\n",
      "English-based 0.44239795207977295\n",
      "king/sultan 0.4620862901210785\n",
      "Army's 0.4441150724887848\n",
      "lapses 0.4157409071922302\n",
      "Tennyson\" 0.42600560188293457\n",
      "organic. 0.45824435353279114\n",
      "near-potable 0.43781280517578125\n",
      "Army's 0.4559389352798462\n",
      "ow 0.4266413450241089\n",
      "megohm 0.4318270981311798\n",
      "ow 0.49222639203071594\n",
      "Pacífico 0.4489041566848755\n",
      "slough 0.45676031708717346\n",
      "NoMatch 0\n",
      "fourth-best 0.45501816272735596\n",
      "ex-Celibate 0.4366941452026367\n",
      "mixing/production 0.441021203994751\n",
      "leftists 0.4570668339729309\n",
      "totaled 0.42107224464416504\n",
      "L’Arc 0.4277048110961914\n",
      "P2X1 0.4333326518535614\n",
      "Originated 0.4652552902698517\n",
      "NTTR. 0.4270397126674652\n",
      "Proximity 0.45350390672683716\n",
      "Sunkari 0.44620800018310547\n",
      "NTTR. 0.43068718910217285\n",
      "Deusch 0.4233994483947754\n",
      "squeal 0.4291856288909912\n",
      "«ov» 0.44574224948883057\n",
      "leptorhynchus 0.4306093156337738\n",
      "EFP 0.43367207050323486\n",
      "Squalea 0.4315757751464844\n",
      "Arnheim 0.4711763858795166\n",
      "«ov» 0.44958755373954773\n",
      "NoMatch 0\n",
      "astronauts) 0.45177334547042847\n",
      "editorialist 0.4619101285934448\n",
      "Outlander 0.4220156669616699\n",
      "\"That's 0.4520559310913086\n",
      "higher-power 0.48590365052223206\n",
      "interiors 0.43318355083465576\n",
      "Durling 0.4403160810470581\n",
      "ain') 0.46835559606552124\n",
      "3)Hancock 0.4405689835548401\n",
      "Takaaki 0.4184957444667816\n",
      "Denying 0.43910467624664307\n",
      "on-the-ground 0.4345960021018982\n",
      "vidhanam 0.46631920337677\n",
      "Caterpillar-Motoren 0.4670048952102661\n",
      "18203 0.44499343633651733\n",
      "adhesins 0.43303316831588745\n",
      "Melon's 0.44717317819595337\n",
      "quiting 0.4550962448120117\n",
      "year—189 0.43746286630630493\n",
      "Bayonet 0.4641581177711487\n",
      "NoMatch 0\n",
      "CHK2 0.4260380268096924\n",
      "vidhanam 0.45508426427841187\n",
      "live-shows 0.4321790635585785\n",
      "Chengdu's 0.46399134397506714\n",
      "“Severnie 0.4127960801124573\n",
      "Ömer 0.45834699273109436\n",
      "Twaron) 0.45053979754447937\n",
      "Dancin\"' 0.43457621335983276\n",
      "Battuer 0.4890119433403015\n",
      "zero-copy 0.441845178604126\n",
      "අයට 0.45616498589515686\n",
      "trust) 0.5246379971504211\n",
      "breakwaters 0.45385199785232544\n",
      "Rausu 0.4562351703643799\n",
      "consultants 0.4476548433303833\n",
      "theatres 0.4375019073486328\n",
      "Paciorek 0.4736776053905487\n",
      "Paciorek 0.45034873485565186\n",
      "brevis\" 0.454172819852829\n",
      "fame) 0.49006760120391846\n",
      "NoMatch 0\n",
      "Johore 0.46053582429885864\n",
      "labial-velar 0.4501904547214508\n",
      "Marie-Catherine 0.4459012448787689\n",
      "Bengals-Miami 0.4297157824039459\n",
      "subversives. 0.46434295177459717\n",
      "Swallows 0.4456343948841095\n",
      "Bachi 0.4762401580810547\n",
      "subversives. 0.4810357391834259\n",
      "subversives. 0.5559329390525818\n",
      "13,651 0.41735008358955383\n",
      "Gumball 0.4508472681045532\n",
      "Mercier 0.4315953850746155\n",
      "2006—2007 0.47315484285354614\n",
      "plunder 0.4365638494491577\n",
      "13,651 0.4268009066581726\n",
      "Misma 0.4285314083099365\n",
      "Mercier 0.4589296579360962\n",
      "subversives. 0.48648160696029663\n",
      "subversives. 0.4530225098133087\n",
      "13,651 0.451107382774353\n",
      "NoMatch 0\n",
      "Özel 0.4248247742652893\n",
      "1941–43 0.4568314850330353\n",
      "Mercier 0.47431522607803345\n",
      "wizards 0.45308876037597656\n",
      "Colgate-Palmolive 0.4349139332771301\n",
      "mis-quoted 0.44567739963531494\n",
      "brews 0.4654666483402252\n",
      "aspen 0.4444085955619812\n",
      "scriptroes 0.40645983815193176\n",
      "hoisted 0.4189280867576599\n",
      "0.47% 0.43731722235679626\n",
      "0.47% 0.4157024323940277\n",
      "non-accredited 0.4148545265197754\n",
      "aspen 0.46886110305786133\n",
      "Kurumada's 0.48322975635528564\n",
      "rice 0.4400135278701782\n",
      "Abbeyfeale 0.41488826274871826\n",
      "Villamontes 0.4320690631866455\n",
      "simpletons 0.44540923833847046\n",
      "Alecia 0.4340962767601013\n",
      "NoMatch 0\n",
      "flammeus\" 0.4399886727333069\n",
      "Contagiándose 0.4840281307697296\n",
      "split-personality 0.43182849884033203\n",
      "Gaviidae 0.43178918957710266\n",
      "TheDwarf 0.42670080065727234\n",
      "Newars 0.5057429671287537\n",
      "interpretative 0.44278568029403687\n",
      "mandobass 0.45676374435424805\n",
      "helmets 0.44395315647125244\n",
      "1939—the 0.47079160809516907\n",
      "1939—the 0.47941887378692627\n",
      "Businengue 0.43078330159187317\n",
      "Businengue 0.47794103622436523\n",
      "Quadrilateral 0.4288378059864044\n",
      "1939—the 0.5150463581085205\n",
      "Monck 0.42306533455848694\n",
      "Q3 0.444119930267334\n",
      "Orangé 0.43841683864593506\n",
      "inflative 0.44135957956314087\n",
      "Hofmeister's 0.4248355031013489\n",
      "NoMatch 0\n",
      "Businengue 0.5054914951324463\n",
      "quality. 0.43733805418014526\n",
      "1939—the 0.497764527797699\n",
      "late-round 0.4777676463127136\n",
      "Celtic/Folk 0.4457494616508484\n",
      "cultivated 0.4400070905685425\n",
      "ECE).” 0.45768845081329346\n",
      "Virodene 0.4663638174533844\n",
      "Oriens 0.4600936770439148\n",
      "evil-minded 0.42370349168777466\n",
      "Tipper 0.4587816596031189\n",
      "Holt) 0.4602046608924866\n",
      "‘‘yangoyang’’ 0.4628128707408905\n",
      "Piia 0.4441434144973755\n",
      "Wissenschaften\" 0.4560697674751282\n",
      "prudent!'\" 0.46506065130233765\n",
      "sculptures 0.43695253133773804\n",
      "Maissa 0.4612082839012146\n",
      "Moynahan 0.44472217559814453\n",
      "Engagements 0.4656251072883606\n",
      "NoMatch 0\n",
      "24.20% 0.4476793706417084\n",
      "Ducky 0.44356364011764526\n",
      "Wissenschaften\" 0.4494797885417938\n",
      "Creeper 0.4491927921772003\n",
      "Wissenschaften\" 0.437808096408844\n",
      "Creeper 0.5044795870780945\n",
      "Notre-Dame-de-Nazareth 0.4316751956939697\n",
      "artisanship 0.4543813467025757\n",
      "Bio-X 0.4288750886917114\n",
      "BendFilm 0.42477327585220337\n",
      "Korle 0.4397581219673157\n",
      "Georges-Henri 0.4830355644226074\n",
      "insulating 0.482128381729126\n",
      "CJM) 0.4884132146835327\n",
      "Roadshow. 0.46052682399749756\n",
      "COMPUTEX 0.45931828022003174\n",
      "33.2%) 0.4407469630241394\n",
      "রঞ্জিকা\" 0.4217642843723297\n",
      "Denters 0.466366708278656\n",
      "Engage 0.4255220890045166\n",
      "NoMatch 0\n",
      "\"double 0.4316418170928955\n",
      "MegaCon 0.4733595848083496\n",
      "Anti-Gag 0.454134464263916\n",
      "Trafford(which 0.4395409822463989\n",
      "purpose-made 0.4274178445339203\n",
      "wieczór 0.4235110282897949\n",
      "Collector\" 0.4509405195713043\n",
      "Kriatec 0.4501360058784485\n",
      "bitter) 0.4195762276649475\n",
      "suspensory 0.4466714560985565\n",
      "Gunboats 0.4263085126876831\n",
      "innovates 0.4617551565170288\n",
      "Al-Ahram 0.43719619512557983\n",
      "Genevois 0.42834436893463135\n",
      "flaps 0.4219725728034973\n",
      "Massacres 0.4372686445713043\n",
      "HSI64-36-RGB 0.46319809556007385\n",
      "Amory 0.4189940094947815\n",
      "12-part 0.43297863006591797\n",
      "Cassels 0.4767254590988159\n",
      "NoMatch 0\n",
      "Tompkins's 0.4188849627971649\n",
      "Leedon's 0.4444982409477234\n",
      "~200 0.46318385004997253\n",
      "~200 0.46684205532073975\n",
      "Vetera 0.4152184724807739\n",
      "Pat-- 0.4199375808238983\n",
      "intellectual 0.4510808289051056\n",
      "18,632 0.4418955445289612\n",
      "Kanor 0.43869003653526306\n",
      "Pat-- 0.4397892355918884\n",
      "x'plorer-system 0.43067866563796997\n",
      "White-throated 0.4743095636367798\n",
      "casual-dining 0.44114530086517334\n",
      "fiftieth 0.46394091844558716\n",
      "Weeping 0.4558897614479065\n",
      "statement.. 0.45592206716537476\n",
      "21.7-km 0.4454836845397949\n",
      "Dorah 0.4384339153766632\n",
      "girls) 0.49294543266296387\n",
      "trades-unionism 0.4584120213985443\n",
      "NoMatch 0\n",
      "1475 0.4351138472557068\n",
      "Lutfisk 0.44455385208129883\n",
      "cantante 0.443327933549881\n",
      "easterly 0.45189914107322693\n",
      "2Σ* 0.43216943740844727\n",
      "girls) 0.4577646255493164\n",
      "ὄργανον 0.5007688999176025\n",
      "yet-to-be 0.43862879276275635\n",
      "Sassanide 0.405194491147995\n",
      "statement.. 0.4454807639122009\n",
      "Dorah 0.43707767128944397\n",
      "Seidman 0.4752010107040405\n",
      "Molotov-Ribbentrop 0.4296036660671234\n",
      "licorice 0.43434008955955505\n",
      "teases 0.446276992559433\n",
      "Shinobi\" 0.5315178632736206\n",
      "Anglo-Dutch 0.44224247336387634\n",
      "ex-commissioners 0.47534576058387756\n",
      "kimono 0.4476514458656311\n",
      "Magnificat 0.44164296984672546\n",
      "NoMatch 0\n",
      "Geirionydd 0.49946677684783936\n",
      "dunce 0.4429534673690796\n",
      "Geirionydd 0.4782881736755371\n",
      "one-half 0.44254371523857117\n",
      "non-obligatory 0.4438045620918274\n",
      "108 0.41528964042663574\n",
      "cockroaches. 0.4811447858810425\n",
      "Origen 0.4562627077102661\n",
      "vyssináda\" 0.44012588262557983\n",
      "Patriots<br> 0.42871254682540894\n",
      "pike-and-shot 0.45623543858528137\n",
      "Lothair 0.4562614858150482\n",
      "Libreville 0.4345130920410156\n",
      "\"Fó\") 0.4385024607181549\n",
      "Children's 0.45831960439682007\n",
      "callsign) 0.42579424381256104\n",
      "Designers’ 0.47920334339141846\n",
      "renin-angiotensin 0.4472176730632782\n",
      "district,a 0.42654794454574585\n",
      "house-like 0.459663987159729\n",
      "NoMatch 0\n",
      "spraying 0.43476250767707825\n",
      "Dowry 0.43838751316070557\n",
      "Vodaas 0.43518364429473877\n",
      "Fox 0.5106055736541748\n",
      "“\"Rembrandt\"” 0.44366949796676636\n",
      "Kherson 0.4781133532524109\n",
      "Belova 0.44686034321784973\n",
      "circus's 0.41695722937583923\n",
      "Langavat's 0.4411410093307495\n",
      "Children's 0.42956122756004333\n",
      "Children's 0.43254709243774414\n",
      "joking 0.46116435527801514\n",
      "Haloun 0.4294884204864502\n",
      "Ulanhu 0.5053053498268127\n",
      "refill 0.44723257422447205\n",
      "Mythili 0.4388549327850342\n",
      "22.00% 0.4564957618713379\n",
      "chocolatier 0.4555397927761078\n",
      "300B 0.4597603976726532\n",
      "d'administration 0.47192642092704773\n",
      "NoMatch 0\n",
      "Mythili 0.4134773313999176\n",
      "deerskin 0.4514334797859192\n",
      "Ichkerian 0.43772539496421814\n",
      "Hufford 0.4487949311733246\n",
      "\"Willow 0.47782647609710693\n",
      "immeasurable 0.45564988255500793\n",
      "Crescenzio 0.4700937271118164\n",
      "cutoff 0.46020081639289856\n",
      "earldoms 0.48957884311676025\n",
      "Crescenzio 0.45620638132095337\n",
      "Post-education 0.4472099244594574\n",
      "Triads\" 0.4256483316421509\n",
      "B’s 0.4552730321884155\n",
      "Hina 0.43953144550323486\n",
      "subprojects 0.4491904377937317\n",
      "Malyy 0.41439831256866455\n",
      "Bongor 0.4799332320690155\n",
      "Kuvo 0.4344305694103241\n",
      "Banner 0.4372217059135437\n",
      "Cynthiana 0.4520603120326996\n",
      "NoMatch 0\n",
      "தேவஸ்தானம்) 0.473823606967926\n",
      "dean's 0.42439448833465576\n",
      "Mid-morning 0.45795831084251404\n",
      "Chaitre 0.4437335431575775\n",
      "trajectory 0.45475098490715027\n",
      "D'Oliveira 0.48427343368530273\n",
      "38-39 0.45424675941467285\n",
      "ibises 0.4881366491317749\n",
      "Sandback 0.4648057818412781\n",
      "“Architecture 0.42311713099479675\n",
      "Yang's 0.46585890650749207\n",
      "Gudinski 0.44980648159980774\n",
      "Imami 0.4313112199306488\n",
      "...going 0.5038668513298035\n",
      "Cotman 0.4164138734340668\n"
     ]
    }
   ],
   "source": [
    "for line in family:\n",
    "    c1, c2, c3, c4 = line\n",
    "    nomatch = model.doesnt_match(line)\n",
    "    if check_contain(line):\n",
    "        w, p = model.most_similar(positive=[c2, c3], negative=[c1], topn=1)[0]\n",
    "        print(w, p)\n",
    "    else:\n",
    "        print(\"NoMatch\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93. アナロジータスクの正解率の計算\n",
    "92で作ったデータを用い，各モデルのアナロジータスクの正解率を求めよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 94. WordSimilarity-353での類似度計算\n",
    "The WordSimilarity-353 Test Collectionの評価データを入力とし，1列目と2列目の単語の類似度を計算し，各行の末尾に類似度の値を追加するプログラムを作成せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95. WordSimilarity-353での評価\n",
    "94で作ったデータを用い，各モデルが出力する類似度のランキングと，人間の類似度判定のランキングの間のスピアマン相関係数を計算せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 96. 国名に関するベクトルの抽出\n",
    "word2vecの学習結果から，国名に関するベクトルのみを抜き出せ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 97. k-meansクラスタリング\n",
    "96の単語ベクトルに対して，k-meansクラスタリングをクラスタ数k=5k=5として実行せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98. Ward法によるクラスタリング\n",
    "96の単語ベクトルに対して，Ward法による階層型クラスタリングを実行せよ．さらに，クラスタリング結果をデンドログラムとして可視化せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. t-SNEによる可視化\n",
    "96の単語ベクトルに対して，ベクトル空間をt-SNEで可視化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

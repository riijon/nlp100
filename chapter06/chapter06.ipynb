{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"nlp.txt\", 'r') as f:\n",
    "    nlp = \" \".join(f.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50. 文区切り\n",
    "(. or ; or : or ? or !) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = '[.|;|:|?|!]\\s+([A-Z])'\n",
    "sentences = []\n",
    "split_line = re.split(p, nlp)\n",
    "sentences.append(split_line[0])\n",
    "for i in range(1, len(split_line), 2):\n",
    "    sentences.append(split_line[i] + split_line[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('50.txt', 'w') as f:\n",
    "    for s in sentences:\n",
    "        f.write(s) \n",
    "        f.write(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 51. 単語の切り出し\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('51.txt', 'w') as f:\n",
    "    for s in sentences:\n",
    "        for w in s.split(' '):\n",
    "            if w: \n",
    "                f.write(w)\n",
    "                f.write('\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 52. ステミング\n",
    "\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装としてstemmingモジュールを利用するとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stemming.porter2 import stem\n",
    "with open('51.txt', 'r') as f:\n",
    "    words = f.readlines()\n",
    "with open('52.txt', 'w') as f:\n",
    "    for w in words:\n",
    "        word = w[:-1]\n",
    "        line = word + \"\\t\" + stem(word) + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 53. Tokenization\n",
    "Stanford Core NLPを用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# java -cp \"*\" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file nlp.txt\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('nlp.txt.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('53.txt', 'w') as f:\n",
    "    for child in root.iter('word'):\n",
    "        f.write(child.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 54. 品詞タグ付け\n",
    "Stanford Core NLPの解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['word', 'lemma', 'CharacterOffsetBegin', 'CharacterOffsetEnd', 'POS', 'NER', 'Speaker']\n",
    "with open('54.txt', 'w') as f:\n",
    "    for child in root.iter('token'):\n",
    "        word = child.find('word').text\n",
    "        lemma = child.find('lemma').text\n",
    "        pos = child.find('POS').text\n",
    "        line = word + \"\\t\" + lemma +\"\\t\" + pos\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 55. 固有表現抽出\n",
    "入力文中の人名をすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('55.txt', 'w') as f:\n",
    "    for child in root.iter('token'):\n",
    "        if child.find('NER').text == \"PERSON\":\n",
    "            word = child.find('word').text\n",
    "            f.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 56. 共参照解析\n",
    "Stanford Core NLPの共参照解析の結果に基づき，文中の参照表現（mention）を代表参照表現（representative mention）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n",
      "{'representative': 'true'}\n"
     ]
    }
   ],
   "source": [
    "mentions =[[m for m in child.iter('mention')] for child in root.iter('coreference')]\n",
    "for x in mentions:\n",
    "    print(x[0].attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

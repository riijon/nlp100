{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章: ベクトル空間法 (I)\n",
    "\n",
    "enwiki-20150112-400-r10-105752.txt.bz2は，2015年1月12日時点の英語のWikipedia記事のうち，約400語以上で構成される記事の中から，ランダムに1/10サンプリングした105,752記事のテキストをbzip2形式で圧縮したものである．このテキストをコーパスとして，単語の意味を表すベクトル（分散表現）を学習したい．第9章の前半では，コーパスから作成した単語文脈共起行列に主成分分析を適用し，単語ベクトルを学習する過程を，いくつかの処理に分けて実装する．第9章の後半では，学習で得られた単語ベクトル（300次元）を用い，単語の類似度計算やアナロジー（類推）を行う．\n",
    "\n",
    "なお，問題83を素直に実装すると，大量（約7GB）の主記憶が必要になる． メモリが不足する場合は，処理を工夫するか，1/100サンプリングのコーパスenwiki-20150112-400-r100-10576.txt.bz2を用いよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80. コーパスの整形\n",
    "文を単語列に変換する最も単純な方法は，空白文字で単語に区切ることである． ただ，この方法では文末のピリオドや括弧などの記号が単語に含まれてしまう． そこで，コーパスの各行のテキストを空白文字でトークンのリストに分割した後，各トークンに以下の処理を施し，単語から記号を除去せよ．\n",
    "\n",
    "+ トークンの先頭と末尾に出現する次の文字を削除: .,!?;:()[]'\"\n",
    "+ 空文字列となったトークンは削除\n",
    "\n",
    "以上の処理を適用した後，トークンをスペースで連結してファイルに保存せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# head -n28443 enwiki-20150112-400-r100-10576.txt > enwiki.txt\n",
    "with open('enwiki.txt', 'r') as f:\n",
    "    delete_words = \".,!?;:()[]'\" + '\"'\n",
    "    corpus = []\n",
    "    for line in f.readlines():\n",
    "        for token in line[:-1].split():\n",
    "            if token[0] in delete_words:\n",
    "                token = token[1:]\n",
    "            if len(token) == 0:\n",
    "                break\n",
    "            if token[-1] in delete_words:\n",
    "                token = token[:-1]\n",
    "            if token:\n",
    "                corpus.append(token)\n",
    "with open('corpus.txt', 'w') as f:\n",
    "    f.write(\" \".join(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 81. 複合語からなる国名への対処\n",
    "英語では，複数の語の連接が意味を成すことがある．例えば，アメリカ合衆国は\"United States\"，イギリスは\"United Kingdom\"と表現されるが，\"United\"や\"States\"，\"Kingdom\"という単語だけでは，指し示している概念・実体が曖昧である．そこで，コーパス中に含まれる複合語を認識し，複合語を1語として扱うことで，複合語の意味を推定したい．しかしながら，複合語を正確に認定するのは大変むずかしいので，ここでは複合語からなる国名を認定したい．\n",
    "\n",
    "インターネット上から国名リストを各自で入手し，80のコーパス中に出現する複合語の国名に関して，スペースをアンダーバーに置換せよ．例えば，\"United States\"は\"United_States\"，\"Isle of Man\"は\"Isle_of_Man\"になるはずである．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.projectvisa.com/fullcountrylist.asp\n",
    "with open('country.txt', 'r') as f:\n",
    "    countries = [x[:-1] for x in f.readlines() if \" \" in x]\n",
    "\n",
    "with open('corpus.txt', 'r') as f:\n",
    "    corpus = f.read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in countries:\n",
    "    corpus = corpus.replace(c, c.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_list = corpus.split(\" \")\n",
    "dictionary = np.array(list(set(corpus_list)))\n",
    "T = len(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 82. 文脈の抽出\n",
    "81で作成したコーパス中に出現するすべての単語$t$に関して，単語$t$と文脈語$c$のペアをタブ区切り形式ですべて書き出せ．ただし，文脈語の定義は次の通りとする．\n",
    "\n",
    "+ ある単語$t$の前後$d$単語を文脈語$c$として抽出する（ただし，文脈語に単語$t$そのものは含まない）\n",
    "+ 単語$t$を選ぶ度に，文脈幅$d$は$\\{1,2,3,4,5\\}$の範囲でランダムに決める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_d():\n",
    "    d = np.random.randint(-5, 5)\n",
    "    if d == 0:\n",
    "        d = get_d()\n",
    "    return d\n",
    "\n",
    "with open(\"82.txt\", \"w\") as f:\n",
    "    for i, t in enumerate(corpus_list):\n",
    "        d = get_d() \n",
    "        if (i + d >= 0) and  (i + d < T):\n",
    "            c = corpus_list[i + d]\n",
    "            if c != t:\n",
    "                line = t + \"\\t\" + c + \"\\n\"\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 83. 単語／文脈の頻度の計測\n",
    "82の出力を利用し，以下の出現分布，および定数を求めよ．\n",
    "\n",
    "+ $f(t,c)$: 単語$t$と文脈語$c$の共起回数\n",
    "+ $f(t,∗)$: 単語$t$の出現回数\n",
    "+ $f(∗,c)$: 文脈語$c$の出現回数\n",
    "+ $N$: 単語と文脈語のペアの総出現回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tc = pd.read_csv(\"82.txt\", sep=\"\\t\", header=None, names=[\"t\", \"c\"])\n",
    "tc = tc[tc.t != tc.c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284196"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(tc.index)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism</td>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>advocates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>political</td>\n",
       "      <td>advocates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t          c\n",
       "0   Anarchism  political\n",
       "1          is          a\n",
       "2           a  advocates\n",
       "3   political  advocates\n",
       "4  philosophy       that"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_t = tc.groupby('t').count()\n",
    "f_c = tc.groupby('c').count()\n",
    "tc['count'] = tc['t']\n",
    "f_tc = tc.groupby(list(\"tc\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    24810\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_t.ix['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t    24842\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_c.ix['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tc.ix[('a', 'that')][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 84. 単語文脈行列の作成\n",
    "83の出力を利用し，単語文脈行列$X$を作成せよ．ただし，行列$X$の各要素$X_{tc}$は次のように定義する．\n",
    "\n",
    "+ $f(t,c)≥10$ならば，$X_{tc}=PPMI(t,c)=max\\{log \\frac{N×f(t,c)}{f(t,∗)×f(∗,c)},0\\}$\n",
    "+ $f(t,c)<10$ならば，$X_{tc}=0$\n",
    "\n",
    "ここで，$PPMI(t,c)$はPositive Pointwise Mutual Information（正の相互情報量）と呼ばれる統計量である．\n",
    "なお，行列$X$の行数・列数は数百万オーダとなり，行列のすべての要素を主記憶上に載せることは無理なので注意すること．幸い，行列$X$のほとんどの要素は$0$になるので，非$0$の要素だけを書き出せばよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>of</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>in</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "t  c         \n",
       "1  of      13\n",
       "   on      11\n",
       "   the     19\n",
       "   was     10\n",
       "10 in      10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tc[f_tc['count'] >= 10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8520"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_tc[f_tc['count'] >= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from math import log\n",
    "W = len(dictionary)\n",
    "X = sparse.lil_matrix((W, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vile'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26197"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dictionary == 'is')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[26197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>on</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>was</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>in</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t    c  count\n",
       "0   1   of     13\n",
       "1   1   on     11\n",
       "2   1  the     19\n",
       "3   1  was     10\n",
       "4  10   in     10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = f_tc[f_tc['count'] >= 10].reset_index()\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_t = f_t.reset_index()\n",
    "f_t.columns = [['t', 'ft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_c = f_c.reset_index()\n",
    "f_c.columns = [['c', 'fc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>count</th>\n",
       "      <th>ft</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "      <td>441</td>\n",
       "      <td>49921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>15</td>\n",
       "      <td>276</td>\n",
       "      <td>49921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>of</td>\n",
       "      <td>11</td>\n",
       "      <td>647</td>\n",
       "      <td>49921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>of</td>\n",
       "      <td>153</td>\n",
       "      <td>1520</td>\n",
       "      <td>49921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>of</td>\n",
       "      <td>58</td>\n",
       "      <td>621</td>\n",
       "      <td>49921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t   c  count    ft     fc\n",
       "0     1  of     13   441  49921\n",
       "1    10  of     15   276  49921\n",
       "2   100  of     11   647  49921\n",
       "3    18  of    153  1520  49921\n",
       "4  2000  of     58   621  49921"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.merge(X_df, f_t, on='t')\n",
    "X_df = pd.merge(X_df, f_c, on='c')\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df['ppmi1'] = (N * X_df['count']) / (X_df['ft'] * X_df['fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>count</th>\n",
       "      <th>ft</th>\n",
       "      <th>fc</th>\n",
       "      <th>ppmi1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "      <td>441</td>\n",
       "      <td>49921</td>\n",
       "      <td>0.758321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>15</td>\n",
       "      <td>276</td>\n",
       "      <td>49921</td>\n",
       "      <td>1.398074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>of</td>\n",
       "      <td>11</td>\n",
       "      <td>647</td>\n",
       "      <td>49921</td>\n",
       "      <td>0.437357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>of</td>\n",
       "      <td>153</td>\n",
       "      <td>1520</td>\n",
       "      <td>49921</td>\n",
       "      <td>2.589381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>of</td>\n",
       "      <td>58</td>\n",
       "      <td>621</td>\n",
       "      <td>49921</td>\n",
       "      <td>2.402616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t   c  count    ft     fc     ppmi1\n",
       "0     1  of     13   441  49921  0.758321\n",
       "1    10  of     15   276  49921  1.398074\n",
       "2   100  of     11   647  49921  0.437357\n",
       "3    18  of    153  1520  49921  2.589381\n",
       "4  2000  of     58   621  49921  2.402616"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6409"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_df[X_df['ppmi1'] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('X.txt', 'w') as f:\n",
    "    line = \"t_i,c_i,ppmi\\n\"\n",
    "    f.write(line)\n",
    "    for row in X_df[X_df['ppmi1'] > 1].iterrows():\n",
    "        t = row[1]['t']\n",
    "        c = row[1]['c']\n",
    "        t_i = np.where(dictionary == t)[0][0]\n",
    "        c_i = np.where(dictionary == c)[0][0]\n",
    "        ppmi = log(row[1]['ppmi1'])\n",
    "        line = str(t_i) + \",\" + str(c_i) + \",\" + str(ppmi) + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_csv = pd.read_csv('X.txt')\n",
    "for row in X_csv.iterrows():\n",
    "    X[row[1]['t_i'], row[1]['c_i']] = row[1]['ppmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 85. 主成分分析による次元圧縮\n",
    "84で得られた単語文脈行列に対して，主成分分析を適用し，単語の意味ベクトルを300次元に圧縮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/33603787/performing-pca-on-large-sparse-matrix-by-using-sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "clf = TruncatedSVD(300)\n",
    "Xpca = clf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.68889740e-15,   3.94710245e-15,  -6.07140799e-15, ...,\n",
       "          1.92331748e-16,   1.67572173e-16,  -1.54882369e-16],\n",
       "       [ -4.71660897e-16,   5.45429751e-15,  -1.60533511e-15, ...,\n",
       "         -1.36382128e-16,  -1.94146470e-16,  -1.12592492e-16],\n",
       "       [ -3.22796058e-16,   8.46850367e-16,  -1.00355398e-15, ...,\n",
       "          1.20282575e-16,  -9.80202510e-17,  -2.71811618e-16],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,  -0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,  -0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,  -0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 86. 単語ベクトルの表示\n",
    "85で得た単語の意味ベクトルを読み込み，\"United States\"のベクトルを表示せよ．ただし，\"United States\"は内部的には\"United_States\"と表現されていることに注意せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(word):\n",
    "    i = np.where(dictionary == word)[0][0]\n",
    "    return Xpca[i].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.58660899e-01,  -5.08962569e-01,   1.32330366e+00,\n",
       "          1.54863439e-01,  -1.26987219e-01,   2.19281149e-01,\n",
       "          3.59846323e+00,   4.35852928e-01,  -1.59769966e+00,\n",
       "         -2.21568188e-01,   1.07949071e+00,   1.14404089e+00,\n",
       "          9.25374939e-01,   3.59771463e-01,   3.90410694e+00,\n",
       "          5.55161332e-01,  -1.70299072e+00,  -1.02625177e+00,\n",
       "         -1.61096673e+00,  -8.65139448e-01,   1.20757269e-01,\n",
       "         -7.27082088e-01,  -1.11683726e+00,  -4.33329563e-01,\n",
       "          5.23616016e-01,  -3.78601913e-01,  -2.99316636e-02,\n",
       "          4.50883910e-01,  -3.09245732e-01,  -6.06753826e-01,\n",
       "          5.58668317e-02,  -1.83836602e-01,  -6.51845067e-01,\n",
       "          4.80972015e-01,   3.20178893e-01,  -4.62340266e-01,\n",
       "         -2.97092514e-01,  -1.50879887e-01,   2.63497405e-01,\n",
       "         -7.27013907e-02,   4.95360099e-02,   1.62227699e-01,\n",
       "          8.06535592e-01,  -3.78516184e-01,   1.73879008e-01,\n",
       "          6.58097987e-01,   1.17975763e+00,  -4.26480253e-03,\n",
       "         -3.82881291e-01,  -3.83527435e-01,   2.56137100e-01,\n",
       "          5.53618294e-01,   4.73529835e-01,   4.55133263e-01,\n",
       "         -4.53998857e-02,  -4.83403917e-01,  -8.75859451e-02,\n",
       "          4.73329434e-01,   6.53910643e-01,   2.51376115e-01,\n",
       "          1.08591539e-01,  -1.49678001e-03,   2.64501437e-01,\n",
       "          3.35925357e-03,  -3.50042905e-02,   1.46671570e-01,\n",
       "          5.13073667e-02,  -4.31898572e-02,  -2.15012325e-01,\n",
       "         -7.44633770e-01,   2.62768015e-01,  -6.49201868e-01,\n",
       "          8.71010328e-01,   7.59429366e-02,   1.05993556e-02,\n",
       "         -2.48404402e-01,   2.00939670e-14,  -6.20373264e-01,\n",
       "         -3.21656165e-14,  -3.04094777e-01,   5.13092252e-01,\n",
       "         -3.21170742e-02,   5.65492378e-01,  -4.93272331e-14,\n",
       "          2.70721359e-02,   2.44300454e-01,  -7.80765969e-01,\n",
       "         -1.01281003e+00,   1.62195619e-05,  -7.23445583e-01,\n",
       "          6.03155180e-01,  -4.12385335e-01,   3.79123745e-01,\n",
       "         -7.68211040e-01,  -1.78621235e-01,   4.16290027e-01,\n",
       "         -7.62732399e-01,   3.88568517e-01,   7.89977146e-14,\n",
       "          7.66824408e-02,   4.78194372e-01,  -1.16178824e+00,\n",
       "          1.01216286e+00,  -5.53432841e-01,  -3.12590578e-01,\n",
       "         -1.17672398e-01,  -6.50971425e-01,   3.14951659e-15,\n",
       "         -5.29163013e-02,  -3.39549614e-01,  -4.05209983e-01,\n",
       "         -1.04349063e-01,   2.16423039e-01,  -4.15362684e-13,\n",
       "         -9.56087196e-01,   3.07631074e-01,   6.18129126e-01,\n",
       "          2.60087715e-01,  -1.21401756e-01,   1.21719887e-01,\n",
       "         -2.11691165e-01,   2.29076931e-02,   1.21017581e-01,\n",
       "         -8.21017922e-02,   2.28999161e-01,   6.66158815e-02,\n",
       "         -4.01794588e-01,   6.45821987e-01,   2.30528245e-01,\n",
       "         -2.70243203e-01,  -2.36461261e-01,   3.42343796e-01,\n",
       "          3.79983493e-01,   5.03010389e-01,   5.57281315e-02,\n",
       "          2.56252188e-01,   7.17174681e-01,   3.11608840e-01,\n",
       "         -4.90022161e-01,   1.88527857e-01,   7.82747363e-01,\n",
       "          2.57602998e-01,  -5.25884700e-01,   5.30270295e-13,\n",
       "          8.31541466e-01,  -7.69876155e-02,   4.74420570e-01,\n",
       "         -7.82827387e-02,  -1.15573521e-01,  -8.87481679e-01,\n",
       "          3.13310515e-01,   6.82806387e-02,  -5.48262992e-01,\n",
       "          1.05083127e-01,  -8.62977396e-02,  -1.01158285e+00,\n",
       "          9.21601536e-02,  -5.16236625e-01,  -1.06396547e-01,\n",
       "          4.14082441e-02,  -2.73855369e-01,   4.31842440e-01,\n",
       "          1.26920867e-02,   2.89243140e-01,  -1.61967263e-01,\n",
       "         -2.13261617e-01,   2.17794620e-01,   2.51181390e-03,\n",
       "          2.49145015e-01,  -2.08338178e-01,  -6.98454800e-02,\n",
       "          2.72239479e-01,  -1.76859873e-01,   9.98410111e-02,\n",
       "          2.49344124e-01,   1.01101126e-01,   2.32501478e-01,\n",
       "          2.46408475e-01,  -1.12563728e-01,  -1.81782419e-01,\n",
       "         -1.88989395e-01,  -2.03334465e-03,   2.96467167e-01,\n",
       "          2.32657630e-02,  -4.89004976e-02,  -6.00845347e-02,\n",
       "          3.18256064e-01,  -2.33663246e-01,  -6.12379716e-02,\n",
       "          1.40252343e-01,   1.04668270e-01,   2.10444345e-01,\n",
       "          9.98191098e-02,   1.79396119e-01,  -4.48876785e-01,\n",
       "         -1.73904975e-02,   2.99974741e-01,  -4.32397606e-01,\n",
       "         -4.09011691e-01,   3.09168436e-01,   1.56944003e-02,\n",
       "          1.62081785e-01,   2.41247430e-01,  -9.23992086e-02,\n",
       "         -1.08834588e-01,   3.55850231e-02,  -5.53161209e-02,\n",
       "          1.02664174e-01,  -3.77731960e-02,   5.71414912e-02,\n",
       "          5.01812380e-02,   2.31708801e-02,   4.76205578e-03,\n",
       "          8.72740632e-02,  -1.11194858e-01,   5.64526679e-02,\n",
       "          8.84063575e-04,   2.17582875e-02,   5.75061269e-02,\n",
       "         -1.32596754e-02,   7.35120264e-02,  -1.78196125e-02,\n",
       "          9.68064003e-03,  -3.26271889e-02,   5.38049433e-02,\n",
       "         -4.00889088e-02,   4.39499375e-02,  -2.18768382e-02,\n",
       "         -1.53680194e-02,  -7.15774347e-03,   2.95081298e-03,\n",
       "          1.89238729e-02,   3.08938159e-02,   3.06865331e-02,\n",
       "         -1.11541047e-02,  -2.47542356e-02,   7.84820606e-03,\n",
       "          8.45303866e-03,   4.45996816e-03,  -6.35549489e-03,\n",
       "         -8.25612579e-03,  -1.08920148e-02,   3.91524517e-03,\n",
       "         -2.03022487e-03,  -2.55319720e-04,   1.43215785e-04,\n",
       "         -3.19802750e-19,   2.49207764e-19,  -6.91975750e-20,\n",
       "          5.73564519e-19,   3.64927180e-19,  -9.35015896e-19,\n",
       "         -1.26455284e-19,  -3.59736216e-19,  -4.18281348e-19,\n",
       "         -4.31831263e-19,   4.77030105e-19,  -2.74511433e-19,\n",
       "         -1.49784908e-19,  -1.05398259e-18,  -2.27167231e-19,\n",
       "          4.50625258e-19,  -2.50852664e-19,   1.64142677e-19,\n",
       "          3.91081848e-19,  -7.70281084e-19,  -1.08564141e-19,\n",
       "         -9.85415195e-19,   3.49926866e-20,  -9.09206612e-19,\n",
       "          8.91169872e-20,   1.42352155e-19,   1.16588333e-18,\n",
       "          5.76857727e-20,   2.63711018e-19,   7.08841269e-19,\n",
       "          1.54312177e-19,   1.00701738e-18,  -3.55785096e-19,\n",
       "         -1.92560976e-18,  -1.07594949e-18,   3.94195165e-19,\n",
       "          1.23593009e-19,  -5.59852798e-19,   1.23165872e-20,\n",
       "          2.71043548e-19,  -1.50364968e-18,   4.66679435e-21,\n",
       "          3.75058758e-19,  -3.73965873e-19,   7.03858658e-19,\n",
       "         -5.43117677e-19,   4.47656920e-19,   5.07983226e-19,\n",
       "         -3.42110193e-19,   7.10939507e-19,   3.73682926e-19,\n",
       "          4.21492863e-19,  -6.14056995e-19,   3.45048075e-19]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec(\"United_States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 87. 単語の類似度\n",
    "85で得た単語の意味ベクトルを読み込み，\"United States\"と\"U.S.\"のコサイン類似度を計算せよ．ただし，\"U.S.\"は内部的に\"U.S\"と表現されていることに注意せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058618268924742457"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_word_cs(word1, word2):\n",
    "    return cosine_similarity(vec(word1), vec(word2))[0][0]\n",
    "get_word_cs(\"United_States\", \"U.S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 88. 類似度の高い単語10件\n",
    "85で得た単語の意味ベクトルを読み込み，\"England\"とコサイン類似度が高い10語と，その類似度を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top10(word):\n",
    "    lst=[]\n",
    "    for i, w in enumerate(Xpca[:1000]):\n",
    "        cs = cosine_similarity(vec(word), w.reshape(1, -1))[0][0]\n",
    "        lst.append((dictionary[i], cs))\n",
    "    return pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng_top10 = get_top10(\"England\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>May</td>\n",
       "      <td>0.923128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Europe</td>\n",
       "      <td>0.843394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>music</td>\n",
       "      <td>0.813579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>election</td>\n",
       "      <td>0.781285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>then</td>\n",
       "      <td>0.282207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>influence</td>\n",
       "      <td>0.203258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>manibus</td>\n",
       "      <td>0.171149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Ben-Gurion</td>\n",
       "      <td>0.156187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shinde</td>\n",
       "      <td>0.155307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>skyscrapers</td>\n",
       "      <td>0.141807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "617          May  0.923128\n",
       "927       Europe  0.843394\n",
       "299        music  0.813579\n",
       "961     election  0.781285\n",
       "420         then  0.282207\n",
       "725    influence  0.203258\n",
       "110      manibus  0.171149\n",
       "217   Ben-Gurion  0.156187\n",
       "7         Shinde  0.155307\n",
       "206  skyscrapers  0.141807"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_top10.sort_values(1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 89. 加法構成性によるアナロジー\n",
    "85で得た単語の意味ベクトルを読み込み，vec(\"Spain\") - vec(\"Madrid\") + vec(\"Athens\")を計算し，そのベクトルと類似度の高い10語とその類似度を出力せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec89 = vec(\"Spain\") - vec(\"Madrid\") + vec(\"Athens\")\n",
    "lst=[]\n",
    "for i, w in enumerate(Xpca[:1000]):\n",
    "    cs = cosine_similarity(vec89, w.reshape(1, -1))\n",
    "    lst.append((dictionary[i], cs[0][0]))\n",
    "df89 = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>outside</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>larger</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>road</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>No</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>election</td>\n",
       "      <td>0.499605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>May</td>\n",
       "      <td>0.183763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vespucius)</td>\n",
       "      <td>0.113157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Derzhanski</td>\n",
       "      <td>0.092653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shinde</td>\n",
       "      <td>0.091238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "671     outside  1.000000\n",
       "8        larger  1.000000\n",
       "246        road  1.000000\n",
       "531      Athens  1.000000\n",
       "980          No  1.000000\n",
       "961    election  0.499605\n",
       "617         May  0.183763\n",
       "10   Vespucius)  0.113157\n",
       "211  Derzhanski  0.092653\n",
       "7        Shinde  0.091238"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df89.sort_values(1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
